{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_opt_decision_boundary(w, gamma, p):\n",
    "    # given a linear model plot the decision boundary using the weights of the linear layer\n",
    "    x = np.linspace(-3, 3, 100)\n",
    "    y = -w[0]/w[1] * x - np.log(p/(1-p))/w[1]\n",
    "    plt.plot(x, y, label=\"Optimal Decision Boundary\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(n, d, w, gamma, p):\n",
    "    ys = torch.distributions.Bernoulli(torch.tensor(p)).sample((n, 1))\n",
    "    scaleDown = torch.tensor([1., 1.])\n",
    "    zs = torch.randn(n, d)\n",
    "    xs = (zs) / scaleDown[ys.long()] + gamma * (2*ys-1) * w\n",
    "    return xs.float(), ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_accuracy(xs, ys, w, gamma, p):\n",
    "    temp = 1/(1+torch.exp(2*gamma*torch.matmul(xs, w)))\n",
    "    preds = temp <= p\n",
    "    return (preds == ys[:,0]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_source(xTrain, yTrain, xTest, yTest):\n",
    "    '''\n",
    "    Trains a logistic regression model on the source dataset and returns the model.\n",
    "    '''\n",
    "    model = nn.Sequential(nn.Linear(2, 128), nn.ReLU(), nn.Linear(128, 1))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "    losses = []\n",
    "    for i in tqdm(range(10000)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = torch.sigmoid(model(xTrain))\n",
    "        loss = F.binary_cross_entropy(outputs, yTrain)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt(model, xTarget, epochs = 100000):\n",
    "    '''\n",
    "    Adapts the model to the target dataset and returns the adapted model.\n",
    "    Current code uses Adam since the SGD was very slow.\n",
    "    '''\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "    losses = []\n",
    "    for i in tqdm(range(epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xTarget)\n",
    "\n",
    "        probsPred = torch.sigmoid(outputs)\n",
    "        labelPreds = (probsPred > 0.5).float().detach()\n",
    "        loss = F.binary_cross_entropy(probsPred, labelPreds)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # labelPreds = (outputs > 0).float().detach()\n",
    "        # loss = torch.mean(torch.clamp(1 - outputs.t() * labelPreds, min=0))\n",
    "        # loss = torch.mean(torch.exp(-outputs.t() * labelPreds))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y):\n",
    "    return((model(x) > 0) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "d = 2\n",
    "w = torch.ones(d)/np.sqrt(d)\n",
    "gamma = 0.3\n",
    "pSource = 0.5\n",
    "pTarget = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xSourceTrain, ySourceTrain = gen_data(n, d, w, gamma, pSource)\n",
    "xSourceTest, ySourceTest = gen_data(n, d, w, gamma, pSource)\n",
    "\n",
    "xTargetTrain, yTargetTrain = gen_data(n, d, w, gamma, pTarget)\n",
    "xTargetTest, yTargetTest = gen_data(n, d, w, gamma, pTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes accuracy on source is: tensor(0.6270)\n",
      "Bayes accuracy on target is: tensor(0.9100)\n"
     ]
    }
   ],
   "source": [
    "bAccuSource = bayes_accuracy(xSourceTest, ySourceTest, w, gamma, pSource)\n",
    "bAccuTarget = bayes_accuracy(xTargetTest, yTargetTest, w, gamma, pTarget)\n",
    "print(\"Bayes accuracy on source is:\", bAccuSource)\n",
    "print(\"Bayes accuracy on target is:\", bAccuTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "model = train_on_source(xSourceTrain, ySourceTrain, xSourceTest, ySourceTest)\n",
    "print(\"Accuracy on source is:\", evaluate(model, xSourceTest, ySourceTest))\n",
    "print(\"Accuracy on target is:\", evaluate(model, xTargetTest, yTargetTest))\n",
    "\n",
    "model = adapt(model, xTargetTrain)\n",
    "print(\"Accuracy on source is:\", evaluate(model, xSourceTest, ySourceTest))\n",
    "print(\"Accuracy on target is:\", evaluate(model, xTargetTest, yTargetTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accusBeforeAdapt = collections.defaultdict(list)\n",
    "accusAfterAdapt = collections.defaultdict(list)\n",
    "bayesAccus = collections.defaultdict(list)\n",
    "\n",
    "data = collections.defaultdict(dict)\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "reps = 1\n",
    "for _ in range(reps):\n",
    "    xSourceTrain, ySourceTrain = gen_data(n, d, w, gamma, pSource)\n",
    "    xSourceTest, ySourceTest = gen_data(n, d, w, gamma, pSource)\n",
    "    model = train_on_source(xSourceTrain, ySourceTrain, xSourceTest, ySourceTest)\n",
    "    data[_]['Source'] = [xSourceTrain, ySourceTrain, xSourceTest, ySourceTest]\n",
    "    data[_]['Source_Model'] = copy.deepcopy(model)\n",
    "    for i in range(10):\n",
    "        p = 0.5 + i/20\n",
    "        xTargetTrain, yTargetTrain = gen_data(n, d, w, gamma, p)\n",
    "        xTargetTest, yTargetTest = gen_data(n, d, w, gamma, p)\n",
    "        data[_][p] = [xTargetTrain, yTargetTrain, xTargetTest, yTargetTest]\n",
    "\n",
    "        bAccuTarget = bayes_accuracy(xTargetTest, yTargetTest, w, gamma, p)\n",
    "        bayesAccus[p].append(bAccuTarget)\n",
    "\n",
    "        temp_model = copy.deepcopy(model)\n",
    "        accusBeforeAdapt[p].append(evaluate(temp_model, xTargetTest, yTargetTest))\n",
    "        temp_model = adapt(temp_model, xTargetTrain, epochs=250000)\n",
    "        accusAfterAdapt[p].append(evaluate(temp_model, xTargetTest, yTargetTest))\n",
    "        data[_][str(p)+'_Model'] = copy.deepcopy(temp_model)\n",
    "        print(\" Accu after adapt for\", p, \"is\", accusAfterAdapt[p][-1])\n",
    "# for p in accusAfterAdapt:\n",
    "#     accusBeforeAdapt[p] /= reps\n",
    "#     accusAfterAdapt[p] /= reps\n",
    "#     bayesAccus[p] /= reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(bayesAccus.keys()), list(bayesAccus.values()), label=\"Bayes\")\n",
    "plt.plot(list(bayesAccus.keys()), list(bayesAccus.values()), label=\"Bayes\")\n",
    "plt.scatter(list(accusBeforeAdapt.keys()), list(accusBeforeAdapt.values()), label=\"Linear before adapt\")\n",
    "plt.plot(list(accusBeforeAdapt.keys()), list(accusBeforeAdapt.values()), label=\"Linear before adapt\")\n",
    "plt.scatter(list(accusAfterAdapt.keys()), list(accusAfterAdapt.values()), label=\"Linear after adapt\")\n",
    "plt.plot(list(accusAfterAdapt.keys()), list(accusAfterAdapt.values()), label=\"Linear after adapt\")\n",
    "plt.xlabel(\"probability of positive label\")\n",
    "plt.title(\"n={}, d={}, w={}, gamma={}, lr={}, epochs={}\".format(n, d, w, gamma, 0.00001, 100000))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numNegatives = []\n",
    "for _ in data:\n",
    "    for p in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        preds = data[_][p+'_Model'](data[_][p][0])\n",
    "        numNegatives.append((preds < 0).float().mean().item())\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fe8eaf950b0cf64c1b70de22759d9a144a2595c541b4003711edd1f96d908e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
